---
title: "Descriptive Stats"
author: "Aaron"
date: "7/31/2018"
output: 
  html_document:
    code_folding: hide
    number_sections: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(haven)
library(recipes)
library(pander)
library(skimr)
library(rpart)
library(rsample)
library(hmeasure)
library(rpart.plot)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::read_chunk(here("scripts", "classification", "01load.R"))
knitr::read_chunk(here("scripts", "classification","02preprocess.R"))
knitr::read_chunk(here("scripts", "classification","03rpart.R"))
```

# Descriptivs

```{r load}
```

```{r, results='asis'}
is_binary <- function(x, enforce_numeric = TRUE){
  if(enforce_numeric&(!is.numeric(x)))return(FALSE)
  else{
    length(unique(x))==2
  }
}

data %>%
  mutate_if(is_binary, as.factor) %>% 
  skim() %>% 
  pander()
```

The few missing values are for the following steps mean/mode imputed.

# Classification Tree

First we want to evaluate the out of sample performance of the model. For that propuse I utilze cross-validation. Due to the small N (hence compuation will be fast) I choose leave one out crossvalidation, to get the lowest possible bias. After that I treat the results as if they come from one model to make it possible to utilze nonbinary performance measures. This should yield valid out of sample perfomance estimates.

```{r preprocess}
```

```{r rpart-loocv}
```

## Best Model According to F-Measure

The following plots, can be read as following:

The first line in each node represents the predicted group belonging for that node. The second line represents the estimated probability to belong to the first group, and the last line gives the proportion of the sample that falls into this node. The first node, represent the full sample (line three says 100%). Each split is a logical statement involving one variable of the dataset (e.g. age > 30). If a case resolves this statement to TRUE/yes (e.g a case with age 35) then the case falls into the lefthand node. If it resolves to FALSE/no (ege. age 10) it fals into the righthand node. The endnodes (bottom of the plot) represent the final "ruling" if the tree. There one can read the final predicted probability & class for a case that falls into this node.

```{r}
data_cv_metrics %>%
  filter(F == max(F)) %>% # higher is better
  ungroup() %>% 
  select(H, AUCH, Spec, Sens, TP, FP, TN, FN) %>% 
  .[1,] %>% 
  pander()
```

```{r rpart-full-f}
```

## Best Model According to H-Measure

```{r}
data_cv_metrics %>%
  filter(H == max(H)) %>% 
  ungroup() %>% 
  select(H, AUCH, Spec, Sens, TP, FP, TN, FN) %>% 
  .[1,] %>% 
  pander()
```

```{r rpart-full-h}
```

## Extrem Overfit

Just storing the data without generalizing Do not use that model!

```{r}
recipe %>%
  prep(data, retain = TRUE) %>%
  fit_rpart(model = TRUE, minsplit = 1, minbucket = 1) %>% 
  rpart.plot::rpart.plot()
```

